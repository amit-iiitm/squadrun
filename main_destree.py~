from __future__ import division
from datetime import datetime, timedelta
from pandas import DataFrame, merge, Series
from sklearn.ensemble import RandomForestClassifier
import csv
import bisect
import sklearn
from sklearn.externals import joblib
from sklearn import svm, datasets, cross_validation
from sklearn.cross_validation import train_test_split
from sklearn.grid_search import GridSearchCV
from sklearn.metrics import classification_report, precision_score, recall_score, accuracy_score
from sklearn import tree
from sklearn import preprocessing
from sklearn.metrics import recall_score
from sklearn.metrics import precision_score
from sklearn.metrics import accuracy_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import cohen_kappa_score
from imblearn.under_sampling import RandomUnderSampler
from imblearn.under_sampling import CondensedNearestNeighbour
from imblearn.over_sampling import SMOTE

def totimestamp(dt, axis, epoch=datetime(1970,1,1)):
    dt=datetime.strptime(dt, '%Y-%m-%d %H:%M:%S')
    #print dt
    td = dt - epoch
    # return td.total_seconds()
    return (td.microseconds + (td.seconds + td.days * 86400) * 10**6) / 10**6 

df_tran= DataFrame.from_csv("Fraud_Data.csv", index_col=False)
df_ip= DataFrame.from_csv("IpAddress_to_Country.csv", index_col=False)

print df_tran.shape
print df_ip.shape[0]


#print df_tran['signup_time']
df_tran['signup_time']=df_tran['signup_time'].apply(totimestamp,axis=1)
#print df_tran['signup_time']

df_tran['purchase_time']=df_tran['purchase_time'].apply(totimestamp,axis=1)
#print df_tran['purchase_time']

#use the difference of signup time and purchase time as a feature
df_tran['time_diff']=df_tran['purchase_time'] - df_tran['signup_time']

#print df_tran['time_diff']


def getcountry(dt,axis):
    i=bisect.bisect(df_ip['lower_bound_ip_address'],dt)
    #print i
    if i>=df_ip.shape[0]:
        i=i-1
        #print "end occured, ", i-1
    print df_ip.loc[[i]]['country']
    return df_ip.loc[[i]]['country'].values[0]

df_tran['location']=df_tran['ip_address'].apply(getcountry,axis=1)

print "successful"










#df_tran=df_tran.drop(['user_id','device_id','signup_time','purchase_time','ip_address'],axis=1)
df_target=df_tran['class']
df_data=df_tran.drop(['user_id','device_id','signup_time','purchase_time','ip_address','class'],axis=1)

print df_target.shape
print df_data.shape

#transform the locations onto numeric values
le=preprocessing.LabelEncoder()
df_data['location']=le.fit_transform(df_data['location'])
df_data['source']=le.fit_transform(df_data['source'])
df_data['browser']=le.fit_transform(df_data['browser'])
df_data['sex']=le.fit_transform(df_data['sex'])


#use under sampler methods
#rus = RandomUnderSampler()
#df_data, df_target=rus.fit_sample(df_data,df_target)
#print "Done undersampling"

#use condensed neighbour undersampling
#cnn = CondensedNearestNeighbour()
#df_data, df_target=cnn.fit_sample(df_data,df_target)
#print "done cnn undersampling"


print "using SMOTE oversamplling of minority class"
sm = SMOTE(kind='regular')
df_data, df_target=sm.fit_sample(df_data,df_target)

#split into training and testing data
df_data_train, df_data_test, df_target_train, df_target_test=train_test_split(df_data,df_target,test_size=0.20,random_state=0)
#clf = RandomForestClassifier(n_estimators=200)
clf=tree.DecisionTreeClassifier()
#clf=svm.SVC(class_weight='balanced')
print "strating training"
clf.fit(df_data_train,df_target_train)

print "training done"
pred=clf.predict(df_data_test)
print pred
print type(pred)
for p in pred:
    if p==1:
        print "fraud detected"
print "Recall is, ", recall_score(df_target_test,pred)
print "Precision is, ", precision_score(df_target_test,pred)
print "Accuracy is, ", accuracy_score(df_target_test,pred)
print "F1 score is, ", f1_score(df_target_test,pred)
print "Kappa score is, ", cohen_kappa_score(df_target_test,pred)
print confusion_matrix(df_target_test,pred)
df_target.to_csv('target.csv',index=False)
df_data.to_csv('train_data.csv',index=False)
print "save successful"
